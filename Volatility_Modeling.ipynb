{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from arch import arch_model\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "symbol = 'AAPL'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2023-01-01'\n",
    "\n",
    "stock_data = yf.download(symbol, start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STANDARD ROLLING VS EWMA VOLATILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate volatility using rolling windows and EWMA\n",
    "window = 21 # for rolling calculation\n",
    "span = 21 # for EWMA\n",
    "\n",
    "# Calculate daily return for each consecutive day\n",
    "stock_data['Daily Return'] = stock_data['Adj Close'].pct_change()\n",
    "\n",
    "# Calculate annualized rolling volatility\n",
    "stock_data['Rolling Volatility'] = stock_data['Daily Return'].rolling(window=window).std() * (252**0.5)\n",
    "\n",
    "# Calculate Exonentially Weighted Moving Average (EWMA) Volatility; weights not normalized\n",
    "stock_data['EWMA Volatility'] = stock_data['Daily Return'].ewm(span=span, adjust=False).std() * (252**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GARCH/EGARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a GARCH(1,1) and EGARCH(1,1) model\n",
    "returns = stock_data['Daily Return'].dropna()\n",
    "\n",
    "#GARCH(1,1)\n",
    "garch_model = arch_model(returns, vol='Garch', p=1, q=1, rescale='false')\n",
    "garch_results = garch_model.fit(disp=\"off\")\n",
    "\n",
    "# EGARCH(1,1)\n",
    "egarch_model = arch_model(returns, vol='EGarch', p=1, q=1, rescale='false')\n",
    "egarch_results = egarch_model.fit(disp=\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GARCH/EGARCH: AIC/BIC Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GARCH(1,1) AIC: -3679.9250864093046, BIC: -3661.4182154123087\n",
      "EGARCH(1,1) AIC: -3680.1858665208547, BIC: -3661.6789955238587\n"
     ]
    }
   ],
   "source": [
    "# Extract AIC and BIC for GARCH\n",
    "garch_aic = garch_results.aic\n",
    "garch_bic = garch_results.bic\n",
    "\n",
    "# Extract AIC and BIC for EGARCH\n",
    "egarch_aic = egarch_results.aic\n",
    "egarch_bic = egarch_results.bic\n",
    "\n",
    "print(f\"GARCH(1,1) AIC: {garch_aic}, BIC: {garch_bic}\")\n",
    "print(f\"EGARCH(1,1) AIC: {egarch_aic}, BIC: {egarch_bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GARCH/EGARCH: Out of Sample Forecasting Accuracy with MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GARCH(1,1) MSE: 0.11414691547646583\n",
      "EGARCH(1,1) MSE: 0.11380035779637658\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "split_point = int(len(stock_data) * 0.8)\n",
    "train_data = stock_data[:split_point].copy()\n",
    "test_data = stock_data[split_point:].copy()\n",
    "\n",
    "# Preprocessing\n",
    "train_returns = train_data['Daily Return'].dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
    "test_returns = test_data['Daily Return'].dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Fit the GARCH and EGARCH models on the training data\n",
    "garch_model = arch_model(train_returns, vol='Garch', p=1, q=1, rescale='false')\n",
    "garch_results = garch_model.fit(disp=\"off\")\n",
    "\n",
    "egarch_model = arch_model(train_returns, vol='EGarch', p=1, q=1, rescale='false')\n",
    "egarch_results = egarch_model.fit(disp=\"off\")\n",
    "\n",
    "# Forecast GARCH volatility (analytic method: use model's equation)\n",
    "garch_forecast = garch_results.forecast(horizon=len(test_returns))\n",
    "garch_forecast_volatility = np.sqrt(garch_forecast.variance.values[-1, :])\n",
    "\n",
    "# Forecast EGARCH volatility (simulation method: use average of Monte Carlo simulations)\n",
    "egarch_forecast = egarch_results.forecast(horizon=len(test_returns), method='simulation')\n",
    "egarch_forecast_volatility = np.sqrt(egarch_forecast.variance.values[-1, :])\n",
    "\n",
    "# Observed volatility (use rolling stdev)\n",
    "actual_volatility = test_returns.rolling(window=21).std() * np.sqrt(252)\n",
    "actual_volatility = actual_volatility.dropna()\n",
    "\n",
    "# Align lengths\n",
    "garch_forecast_volatility = garch_forecast_volatility[-len(actual_volatility):]\n",
    "egarch_forecast_volatility = egarch_forecast_volatility[-len(actual_volatility):]\n",
    "\n",
    "# Calculate MSE for GARCH\n",
    "garch_mse = mean_squared_error(actual_volatility, garch_forecast_volatility)\n",
    "\n",
    "# Calculate MSE for EGARCH\n",
    "egarch_mse = mean_squared_error(actual_volatility, egarch_forecast_volatility)\n",
    "\n",
    "print(f\"GARCH(1,1) MSE: {garch_mse}\")\n",
    "print(f\"EGARCH(1,1) MSE: {egarch_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing for LSTM and SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to scale to N(0,1)\n",
    "scaler = StandardScaler()\n",
    "# Reshape to vector\n",
    "X_train = scaler.fit_transform(train_returns.values.reshape(-1, 1))\n",
    "X_test = scaler.transform(test_returns.values.reshape(-1, 1))\n",
    "\n",
    "# Calculate actual volatility (use rolling stdev)\n",
    "actual_volatility = test_returns.rolling(window=21).std() * np.sqrt(252)\n",
    "actual_volatility = actual_volatility.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    }
   ],
   "source": [
    "# Transform training and test data into sequences of 21 time steps (inputs) and corresponding next values (outputs)\n",
    "def create_lstm_input(data, time_step=21):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        X.append(data[i:(i + time_step), 0])\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_step = 21\n",
    "X_train_lstm, y_train_lstm = create_lstm_input(X_train, time_step)\n",
    "X_test_lstm, y_test_lstm = create_lstm_input(X_test, time_step)\n",
    "\n",
    "# Reshape for LSTM (# samples, # time steps, 1 feature)\n",
    "X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n",
    "X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n",
    "\n",
    "# Implement LSTM: 2 LSTM layers, 2 dropout layers, 1 dense layer\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(units=50, return_sequences=False))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(units=1))\n",
    "\n",
    "# Set Adam as optimizer, set MSE as loss function\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train LSTM model\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Forecast with LSTM\n",
    "lstm_predictions = lstm_model.predict(X_test_lstm)\n",
    "lstm_predictions = scaler.inverse_transform(lstm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement SVR\n",
    "X_train_svr = X_train[time_step:-1]  # Removing the first `time_step` samples to align with y_train\n",
    "\n",
    "# Train the SVR model\n",
    "svr_model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.01)\n",
    "svr_model.fit(X_train_svr, train_returns[time_step+1:])\n",
    "\n",
    "# Forecast with SVR\n",
    "svr_predictions = svr_model.predict(X_test)\n",
    "svr_predictions = scaler.inverse_transform(svr_predictions.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare LSTM and SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM MSE: 0.1298044289626367\n",
      "SVR MSE: 0.12963725230596773\n"
     ]
    }
   ],
   "source": [
    "# Align lengths of predictions and actual volatility\n",
    "min_length = min(len(lstm_predictions), len(svr_predictions), len(actual_volatility))\n",
    "lstm_predictions = lstm_predictions[-min_length:]\n",
    "svr_predictions = svr_predictions[-min_length:]\n",
    "actual_volatility = actual_volatility[-min_length:]\n",
    "\n",
    "# Calculate MSE for LSTM and SVR\n",
    "lstm_mse = mean_squared_error(actual_volatility, lstm_predictions)\n",
    "svr_mse = mean_squared_error(actual_volatility, svr_predictions)\n",
    "\n",
    "print(f\"LSTM MSE: {lstm_mse}\")\n",
    "print(f\"SVR MSE: {svr_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
